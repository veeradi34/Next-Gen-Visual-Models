# Autoencoders
Autoencoders are neural networks designed to learn efficient representations of data by compressing input into a latent space (encoding) and then reconstructing it (decoding). They are often used for tasks like dimensionality reduction, noise removal, or generating new data. Autoencoders consist of an encoder, a bottleneck layer, and a decoder. Key types include:

- Vanilla Autoencoders: Basic structure for compression and reconstruction.
- Denoising Autoencoders: Learn to reconstruct data from noisy inputs.
- [Variational Autoencoders (VAEs)](https://youtu.be/fcvYpzHmhvA): Generate new data by modeling a probabilistic latent space.
- Sparse Autoencoders: Promote sparsity in the latent representation for feature learning.
> For an in-depth exploration, refer to this [YouTube playlist](https://youtube.com/playlist?list=PLyFpZIg7OtNRRcaOEdmiz1WEd97VHqfd6&si=IQq8a9772_1PRPUF).

> [Tensorflow tutorial](https://www.tensorflow.org/tutorials/generative/cvae)
